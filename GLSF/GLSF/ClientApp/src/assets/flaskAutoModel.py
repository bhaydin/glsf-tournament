# -*- coding: utf-8 -*-
"""Fish or Not Fish.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NQi7FV2kXd75xTq-n3ttkQJID0eHg0PH
"""

import tensorflow as tf
import os, shutil
import keras
from tensorflow.keras import layers
from keras.models import model_from_json, load_model
from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras import optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import LearningRateScheduler
from PIL import Image
import numpy as np
from skimage import transform
import pyodbc
import base64

from flask import Flask
from flask import Request
from flask_cors import CORS


trainDir = "C:/Users/janecekem/Documents/School/SW Dev Lab/Classification Images/QUT_fish_data/QUT_fish_data/images/training"
validationDir = "C:/Users/janecekem/Documents/School/SW Dev Lab/Classification Images/QUT_fish_data/QUT_fish_data/images/validation"
app = Flask(__name__)
CORS(app)


@app.route('/')
def mainPage():
    return "Hello World"


@app.route("/autoModel", methods=["GET", "POST"])
def makeModel():
    getImages()
    trainModel()


def getImages():
    conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'
                        'Server=tcp:glsf.database.windows.net,1433;'
                        'Database=glsf-msoe;'
                        'UID=glsf-sql-admin;'
                        'PWD=cCceGe9Yt69BfMR5;'
                        'Trusted_Connection=no;')

    cursor = conn.cursor()
    cursor.execute('select Id, Image from [dbo].[Fishes] where isValid = 1;')
    startLen = len("data:image/png;base64,")

    for row in cursor:
        Id = row[0]
        bitString = row[1]
        name = "fishId" + str(Id) + ".jpg"

        if bitString != None and bitString != "None":        
            with open(trainDir + "/fish/" + name, "wb") as f:
                f.write(base64.decodestring(str.encode(bitString[startLen : ])))
                print("Wrote to " + name)


def trainModel():
    model = models.Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu',
                            input_shape=(250, 250, 3)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))

    model.summary()

    model.compile(loss='binary_crossentropy',
                optimizer=optimizers.RMSprop(lr=1e-4),
                metrics=['acc'])

    # All images will be rescaled by 1./255
    train_datagen = ImageDataGenerator(rescale=1./255)
    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
            # This is the target directory
            trainDir,
            # All images will be resized to 150x150
            target_size=(250, 250),
            batch_size=20,
            # Since we use binary_crossentropy loss, we need binary labels
            class_mode='binary')

    validation_generator = test_datagen.flow_from_directory(
            validationDir,
            target_size=(250, 250),
            batch_size=20,
            class_mode='binary')

    tensor_board = keras.callbacks.TensorBoard(log_dir='Graph', histogram_freq=0,  
            write_graph=True, write_images=True)

    # train
    history = model.fit_generator(
        train_generator,
        steps_per_epoch=100,
        epochs=30,
        validation_data=validation_generator,
        validation_steps=50,
        callbacks=[tensor_board])

    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    model.save('C:/Users/janecekem/Documents/School/SW Dev Lab/Fish model/LocalRun/fishClassifier.h5')
    model.save_weights('C:/Users/janecekem/Documents/School/SW Dev Lab/Fish model/LocalRun/fishClassifierWeights.h5', overwrite=True)

    with open('C:/Users/janecekem/Documents/School/SW Dev Lab/Fish model/LocalRun/fishClassifierArchitecture.h5', 'w') as f:
        f.write(model.to_json())
    
    return "Finished"


if __name__=='__main__': app.run()


'''
model = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/fishClassifier.h5')

def load(filename):
  np_image = Image.open(filename)
  np_image = np.array(np_image).astype('float32')/255
  np_image = transform.resize(np_image, (250, 250, 3))
  np_image = np.expand_dims(np_image, axis=0)
  return np_image
'''
